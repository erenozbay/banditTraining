# Maximal Objectives in Multi-Armed Bandits

Experiments from [Maximal Objectives in the Multi-armed Bandit with Applications](https://arxiv.org/abs/2006.06853v6) and its earlier versions live here.

Published in https://pubsonline.informs.org/doi/10.1287/mnsc.2022.00801

Extra sets of experiments as well: the dynamic market simulation and some rotting bandit (due to Seznec et al. "Rotting bandits are no harder than stochastic ones." AISTATS, 2019) implementations.
